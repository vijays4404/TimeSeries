{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing library\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-08T09:29:56.924243Z","iopub.execute_input":"2022-06-08T09:29:56.924739Z","iopub.status.idle":"2022-06-08T09:30:03.950601Z","shell.execute_reply.started":"2022-06-08T09:29:56.924625Z","shell.execute_reply":"2022-06-08T09:30:03.949845Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#showing the dataset\ndfs=[pd.read_csv('../input/heartbeat/ptbdb_'+x+'.csv') for x in ['normal','abnormal']]","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:34:41.052787Z","iopub.execute_input":"2022-06-08T09:34:41.053241Z","iopub.status.idle":"2022-06-08T09:34:41.943264Z","shell.execute_reply.started":"2022-06-08T09:34:41.053208Z","shell.execute_reply":"2022-06-08T09:34:41.942234Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#loading the dataset\ndf[0]\nfor df in dfs:\n    df.columns=list(range(len(df.columns)))","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:34:44.130369Z","iopub.execute_input":"2022-06-08T09:34:44.130905Z","iopub.status.idle":"2022-06-08T09:34:44.137100Z","shell.execute_reply.started":"2022-06-08T09:34:44.130863Z","shell.execute_reply":"2022-06-08T09:34:44.136137Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#concating the dataset\ndf=pd.concat(dfs,axis=0).sample(frac=1.0,random_state=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:54:45.157228Z","iopub.execute_input":"2022-06-08T09:54:45.157791Z","iopub.status.idle":"2022-06-08T09:54:45.201130Z","shell.execute_reply.started":"2022-06-08T09:54:45.157752Z","shell.execute_reply":"2022-06-08T09:54:45.200213Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:38:24.058725Z","iopub.execute_input":"2022-06-08T09:38:24.059202Z","iopub.status.idle":"2022-06-08T09:38:24.103191Z","shell.execute_reply.started":"2022-06-08T09:38:24.059165Z","shell.execute_reply":"2022-06-08T09:38:24.102173Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"            0         1         2         3         4         5         6    \\\n0      1.000000  0.887073  0.774146  0.713224  0.682021  0.699851  0.595840   \n1      1.000000  0.684376  0.395907  0.288863  0.262102  0.231405  0.234160   \n2      1.000000  0.645543  0.270195  0.089833  0.038997  0.064067  0.045265   \n3      0.995881  0.993821  0.959835  0.872297  0.542739  0.054583  0.000000   \n4      0.996020  0.323383  0.109453  0.035821  0.264677  0.342289  0.367164   \n...         ...       ...       ...       ...       ...       ...       ...   \n14545  1.000000  0.979786  0.621879  0.146849  0.000000  0.266944  0.356718   \n14546  1.000000  0.648015  0.424677  0.315160  0.223816  0.156384  0.156863   \n14547  0.931217  1.000000  0.465201  0.150183  0.035409  0.033374  0.049247   \n14548  1.000000  0.588291  0.120570  0.056962  0.136076  0.181646  0.182595   \n14549  0.946429  0.315668  0.063940  0.011521  0.067972  0.151498  0.273618   \n\n            7         8         9    ...  178  179  180  181  182  183  184  \\\n0      0.552749  0.469539  0.481426  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1      0.218811  0.207399  0.212121  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2      0.062674  0.059192  0.057799  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3      0.098867  0.156540  0.302781  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4      0.402985  0.401990  0.420896  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n14545  0.421522  0.450059  0.457788  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14546  0.122908  0.093735  0.122908  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14547  0.070818  0.078958  0.087505  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14548  0.185759  0.178481  0.186076  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14549  0.391705  0.397465  0.425115  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n       185  186  187  \n0      0.0  0.0  1.0  \n1      0.0  0.0  1.0  \n2      0.0  0.0  1.0  \n3      0.0  0.0  1.0  \n4      0.0  0.0  1.0  \n...    ...  ...  ...  \n14545  0.0  0.0  0.0  \n14546  0.0  0.0  1.0  \n14547  0.0  0.0  1.0  \n14548  0.0  0.0  0.0  \n14549  0.0  0.0  1.0  \n\n[14550 rows x 188 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>178</th>\n      <th>179</th>\n      <th>180</th>\n      <th>181</th>\n      <th>182</th>\n      <th>183</th>\n      <th>184</th>\n      <th>185</th>\n      <th>186</th>\n      <th>187</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>0.887073</td>\n      <td>0.774146</td>\n      <td>0.713224</td>\n      <td>0.682021</td>\n      <td>0.699851</td>\n      <td>0.595840</td>\n      <td>0.552749</td>\n      <td>0.469539</td>\n      <td>0.481426</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>0.684376</td>\n      <td>0.395907</td>\n      <td>0.288863</td>\n      <td>0.262102</td>\n      <td>0.231405</td>\n      <td>0.234160</td>\n      <td>0.218811</td>\n      <td>0.207399</td>\n      <td>0.212121</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>0.645543</td>\n      <td>0.270195</td>\n      <td>0.089833</td>\n      <td>0.038997</td>\n      <td>0.064067</td>\n      <td>0.045265</td>\n      <td>0.062674</td>\n      <td>0.059192</td>\n      <td>0.057799</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.995881</td>\n      <td>0.993821</td>\n      <td>0.959835</td>\n      <td>0.872297</td>\n      <td>0.542739</td>\n      <td>0.054583</td>\n      <td>0.000000</td>\n      <td>0.098867</td>\n      <td>0.156540</td>\n      <td>0.302781</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.996020</td>\n      <td>0.323383</td>\n      <td>0.109453</td>\n      <td>0.035821</td>\n      <td>0.264677</td>\n      <td>0.342289</td>\n      <td>0.367164</td>\n      <td>0.402985</td>\n      <td>0.401990</td>\n      <td>0.420896</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14545</th>\n      <td>1.000000</td>\n      <td>0.979786</td>\n      <td>0.621879</td>\n      <td>0.146849</td>\n      <td>0.000000</td>\n      <td>0.266944</td>\n      <td>0.356718</td>\n      <td>0.421522</td>\n      <td>0.450059</td>\n      <td>0.457788</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14546</th>\n      <td>1.000000</td>\n      <td>0.648015</td>\n      <td>0.424677</td>\n      <td>0.315160</td>\n      <td>0.223816</td>\n      <td>0.156384</td>\n      <td>0.156863</td>\n      <td>0.122908</td>\n      <td>0.093735</td>\n      <td>0.122908</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14547</th>\n      <td>0.931217</td>\n      <td>1.000000</td>\n      <td>0.465201</td>\n      <td>0.150183</td>\n      <td>0.035409</td>\n      <td>0.033374</td>\n      <td>0.049247</td>\n      <td>0.070818</td>\n      <td>0.078958</td>\n      <td>0.087505</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14548</th>\n      <td>1.000000</td>\n      <td>0.588291</td>\n      <td>0.120570</td>\n      <td>0.056962</td>\n      <td>0.136076</td>\n      <td>0.181646</td>\n      <td>0.182595</td>\n      <td>0.185759</td>\n      <td>0.178481</td>\n      <td>0.186076</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14549</th>\n      <td>0.946429</td>\n      <td>0.315668</td>\n      <td>0.063940</td>\n      <td>0.011521</td>\n      <td>0.067972</td>\n      <td>0.151498</td>\n      <td>0.273618</td>\n      <td>0.391705</td>\n      <td>0.397465</td>\n      <td>0.425115</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>14550 rows × 188 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#renaming the 187 to label columns\ndf=df.rename({187:'Label'},axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:39.816546Z","iopub.execute_input":"2022-06-08T09:57:39.817789Z","iopub.status.idle":"2022-06-08T09:57:39.827815Z","shell.execute_reply.started":"2022-06-08T09:57:39.817748Z","shell.execute_reply":"2022-06-08T09:57:39.826887Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"y=df[187].copy()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:37:48.429499Z","iopub.execute_input":"2022-06-08T09:37:48.429856Z","iopub.status.idle":"2022-06-08T09:37:48.435105Z","shell.execute_reply.started":"2022-06-08T09:37:48.429805Z","shell.execute_reply":"2022-06-08T09:37:48.434061Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:41:53.237069Z","iopub.execute_input":"2022-06-08T09:41:53.237519Z","iopub.status.idle":"2022-06-08T09:41:53.285631Z","shell.execute_reply.started":"2022-06-08T09:41:53.237485Z","shell.execute_reply":"2022-06-08T09:41:53.284483Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"              0         1         2         3         4         5         6  \\\n0      1.000000  0.887073  0.774146  0.713224  0.682021  0.699851  0.595840   \n1      1.000000  0.684376  0.395907  0.288863  0.262102  0.231405  0.234160   \n2      1.000000  0.645543  0.270195  0.089833  0.038997  0.064067  0.045265   \n3      0.995881  0.993821  0.959835  0.872297  0.542739  0.054583  0.000000   \n4      0.996020  0.323383  0.109453  0.035821  0.264677  0.342289  0.367164   \n...         ...       ...       ...       ...       ...       ...       ...   \n14545  1.000000  0.979786  0.621879  0.146849  0.000000  0.266944  0.356718   \n14546  1.000000  0.648015  0.424677  0.315160  0.223816  0.156384  0.156863   \n14547  0.931217  1.000000  0.465201  0.150183  0.035409  0.033374  0.049247   \n14548  1.000000  0.588291  0.120570  0.056962  0.136076  0.181646  0.182595   \n14549  0.946429  0.315668  0.063940  0.011521  0.067972  0.151498  0.273618   \n\n              7         8         9  ...  178  179  180  181  182  183  184  \\\n0      0.552749  0.469539  0.481426  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1      0.218811  0.207399  0.212121  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2      0.062674  0.059192  0.057799  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3      0.098867  0.156540  0.302781  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4      0.402985  0.401990  0.420896  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n14545  0.421522  0.450059  0.457788  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14546  0.122908  0.093735  0.122908  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14547  0.070818  0.078958  0.087505  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14548  0.185759  0.178481  0.186076  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14549  0.391705  0.397465  0.425115  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n       185  186  Label  \n0      0.0  0.0    1.0  \n1      0.0  0.0    1.0  \n2      0.0  0.0    1.0  \n3      0.0  0.0    1.0  \n4      0.0  0.0    1.0  \n...    ...  ...    ...  \n14545  0.0  0.0    0.0  \n14546  0.0  0.0    1.0  \n14547  0.0  0.0    1.0  \n14548  0.0  0.0    0.0  \n14549  0.0  0.0    1.0  \n\n[14550 rows x 188 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>178</th>\n      <th>179</th>\n      <th>180</th>\n      <th>181</th>\n      <th>182</th>\n      <th>183</th>\n      <th>184</th>\n      <th>185</th>\n      <th>186</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>0.887073</td>\n      <td>0.774146</td>\n      <td>0.713224</td>\n      <td>0.682021</td>\n      <td>0.699851</td>\n      <td>0.595840</td>\n      <td>0.552749</td>\n      <td>0.469539</td>\n      <td>0.481426</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>0.684376</td>\n      <td>0.395907</td>\n      <td>0.288863</td>\n      <td>0.262102</td>\n      <td>0.231405</td>\n      <td>0.234160</td>\n      <td>0.218811</td>\n      <td>0.207399</td>\n      <td>0.212121</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>0.645543</td>\n      <td>0.270195</td>\n      <td>0.089833</td>\n      <td>0.038997</td>\n      <td>0.064067</td>\n      <td>0.045265</td>\n      <td>0.062674</td>\n      <td>0.059192</td>\n      <td>0.057799</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.995881</td>\n      <td>0.993821</td>\n      <td>0.959835</td>\n      <td>0.872297</td>\n      <td>0.542739</td>\n      <td>0.054583</td>\n      <td>0.000000</td>\n      <td>0.098867</td>\n      <td>0.156540</td>\n      <td>0.302781</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.996020</td>\n      <td>0.323383</td>\n      <td>0.109453</td>\n      <td>0.035821</td>\n      <td>0.264677</td>\n      <td>0.342289</td>\n      <td>0.367164</td>\n      <td>0.402985</td>\n      <td>0.401990</td>\n      <td>0.420896</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14545</th>\n      <td>1.000000</td>\n      <td>0.979786</td>\n      <td>0.621879</td>\n      <td>0.146849</td>\n      <td>0.000000</td>\n      <td>0.266944</td>\n      <td>0.356718</td>\n      <td>0.421522</td>\n      <td>0.450059</td>\n      <td>0.457788</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14546</th>\n      <td>1.000000</td>\n      <td>0.648015</td>\n      <td>0.424677</td>\n      <td>0.315160</td>\n      <td>0.223816</td>\n      <td>0.156384</td>\n      <td>0.156863</td>\n      <td>0.122908</td>\n      <td>0.093735</td>\n      <td>0.122908</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14547</th>\n      <td>0.931217</td>\n      <td>1.000000</td>\n      <td>0.465201</td>\n      <td>0.150183</td>\n      <td>0.035409</td>\n      <td>0.033374</td>\n      <td>0.049247</td>\n      <td>0.070818</td>\n      <td>0.078958</td>\n      <td>0.087505</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14548</th>\n      <td>1.000000</td>\n      <td>0.588291</td>\n      <td>0.120570</td>\n      <td>0.056962</td>\n      <td>0.136076</td>\n      <td>0.181646</td>\n      <td>0.182595</td>\n      <td>0.185759</td>\n      <td>0.178481</td>\n      <td>0.186076</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14549</th>\n      <td>0.946429</td>\n      <td>0.315668</td>\n      <td>0.063940</td>\n      <td>0.011521</td>\n      <td>0.067972</td>\n      <td>0.151498</td>\n      <td>0.273618</td>\n      <td>0.391705</td>\n      <td>0.397465</td>\n      <td>0.425115</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>14550 rows × 188 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y=df['Label'].copy()\nx=df.drop('Label',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:43.925242Z","iopub.execute_input":"2022-06-08T09:57:43.926291Z","iopub.status.idle":"2022-06-08T09:57:43.942563Z","shell.execute_reply.started":"2022-06-08T09:57:43.926247Z","shell.execute_reply":"2022-06-08T09:57:43.941099Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.7,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:50.434433Z","iopub.execute_input":"2022-06-08T09:57:50.434837Z","iopub.status.idle":"2022-06-08T09:57:50.459602Z","shell.execute_reply.started":"2022-06-08T09:57:50.434804Z","shell.execute_reply":"2022-06-08T09:57:50.458883Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:55.088697Z","iopub.execute_input":"2022-06-08T09:57:55.089097Z","iopub.status.idle":"2022-06-08T09:57:55.094934Z","shell.execute_reply.started":"2022-06-08T09:57:55.089068Z","shell.execute_reply":"2022-06-08T09:57:55.094092Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"(10185, 187)\n(4365, 187)\n(10185,)\n(4365,)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Training the dataset\ninputs=tf.keras.Input(shape=(x_train.shape[1],))\nx=tf.keras.layers.Dense(64,activation='relu')(inputs)\nx=tf.keras.layers.Dense(64,activation='relu')(inputs)\n\noutputs=tf.keras.layers.Dense(1,activation='sigmoid')(x)\nmodel=tf.keras.Model(inputs=inputs,outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:46:30.759797Z","iopub.execute_input":"2022-06-08T09:46:30.760170Z","iopub.status.idle":"2022-06-08T09:46:30.796385Z","shell.execute_reply.started":"2022-06-08T09:46:30.760142Z","shell.execute_reply":"2022-06-08T09:46:30.795519Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.AUC(name='auc')\n    ])\nhistory=model.fit(\n    x_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=100,\n    callbacks=[\n            tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True)\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:49:00.468206Z","iopub.execute_input":"2022-06-08T09:49:00.468643Z","iopub.status.idle":"2022-06-08T09:49:22.359999Z","shell.execute_reply.started":"2022-06-08T09:49:00.468608Z","shell.execute_reply":"2022-06-08T09:49:22.359205Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"2022-06-08 09:49:00.622796: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n255/255 [==============================] - 2s 4ms/step - loss: 0.4832 - accuracy: 0.7602 - auc: 0.7851 - val_loss: 0.4103 - val_accuracy: 0.8017 - val_auc: 0.8601\nEpoch 2/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.3925 - accuracy: 0.8162 - auc: 0.8774 - val_loss: 0.3861 - val_accuracy: 0.8267 - val_auc: 0.8813\nEpoch 3/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.3672 - accuracy: 0.8324 - auc: 0.8926 - val_loss: 0.3677 - val_accuracy: 0.8301 - val_auc: 0.8968\nEpoch 4/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.3509 - accuracy: 0.8423 - auc: 0.9032 - val_loss: 0.3407 - val_accuracy: 0.8498 - val_auc: 0.9071\nEpoch 5/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.3372 - accuracy: 0.8483 - auc: 0.9110 - val_loss: 0.3359 - val_accuracy: 0.8483 - val_auc: 0.9123\nEpoch 6/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8574 - auc: 0.9168 - val_loss: 0.3225 - val_accuracy: 0.8591 - val_auc: 0.9171\nEpoch 7/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.3129 - accuracy: 0.8682 - auc: 0.9250 - val_loss: 0.3134 - val_accuracy: 0.8660 - val_auc: 0.9241\nEpoch 8/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.3026 - accuracy: 0.8716 - auc: 0.9306 - val_loss: 0.2996 - val_accuracy: 0.8694 - val_auc: 0.9289\nEpoch 9/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2919 - accuracy: 0.8757 - auc: 0.9359 - val_loss: 0.2946 - val_accuracy: 0.8773 - val_auc: 0.9325\nEpoch 10/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.8838 - auc: 0.9401 - val_loss: 0.2938 - val_accuracy: 0.8832 - val_auc: 0.9364\nEpoch 11/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2753 - accuracy: 0.8875 - auc: 0.9433 - val_loss: 0.2758 - val_accuracy: 0.8866 - val_auc: 0.9405\nEpoch 12/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.8967 - auc: 0.9495 - val_loss: 0.2664 - val_accuracy: 0.8930 - val_auc: 0.9448\nEpoch 13/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.8990 - auc: 0.9533 - val_loss: 0.2621 - val_accuracy: 0.8881 - val_auc: 0.9472\nEpoch 14/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2492 - accuracy: 0.9018 - auc: 0.9548 - val_loss: 0.2629 - val_accuracy: 0.8940 - val_auc: 0.9505\nEpoch 15/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2377 - accuracy: 0.9093 - auc: 0.9599 - val_loss: 0.2489 - val_accuracy: 0.9018 - val_auc: 0.9516\nEpoch 16/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2306 - accuracy: 0.9157 - auc: 0.9624 - val_loss: 0.2409 - val_accuracy: 0.9082 - val_auc: 0.9561\nEpoch 17/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2233 - accuracy: 0.9145 - auc: 0.9653 - val_loss: 0.2355 - val_accuracy: 0.9131 - val_auc: 0.9590\nEpoch 18/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2172 - accuracy: 0.9184 - auc: 0.9675 - val_loss: 0.2282 - val_accuracy: 0.9072 - val_auc: 0.9611\nEpoch 19/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2094 - accuracy: 0.9207 - auc: 0.9698 - val_loss: 0.2187 - val_accuracy: 0.9200 - val_auc: 0.9646\nEpoch 20/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.2031 - accuracy: 0.9248 - auc: 0.9717 - val_loss: 0.2159 - val_accuracy: 0.9239 - val_auc: 0.9651\nEpoch 21/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9276 - auc: 0.9740 - val_loss: 0.2146 - val_accuracy: 0.9200 - val_auc: 0.9675\nEpoch 22/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9337 - auc: 0.9761 - val_loss: 0.2036 - val_accuracy: 0.9229 - val_auc: 0.9687\nEpoch 23/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1852 - accuracy: 0.9304 - auc: 0.9770 - val_loss: 0.2048 - val_accuracy: 0.9239 - val_auc: 0.9698\nEpoch 24/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.9379 - auc: 0.9795 - val_loss: 0.1999 - val_accuracy: 0.9283 - val_auc: 0.9706\nEpoch 25/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1733 - accuracy: 0.9388 - auc: 0.9803 - val_loss: 0.1962 - val_accuracy: 0.9288 - val_auc: 0.9703\nEpoch 26/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1706 - accuracy: 0.9377 - auc: 0.9806 - val_loss: 0.1906 - val_accuracy: 0.9323 - val_auc: 0.9720\nEpoch 27/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1659 - accuracy: 0.9432 - auc: 0.9817 - val_loss: 0.1904 - val_accuracy: 0.9303 - val_auc: 0.9742\nEpoch 28/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1614 - accuracy: 0.9427 - auc: 0.9829 - val_loss: 0.1871 - val_accuracy: 0.9293 - val_auc: 0.9746\nEpoch 29/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1589 - accuracy: 0.9445 - auc: 0.9833 - val_loss: 0.1872 - val_accuracy: 0.9308 - val_auc: 0.9737\nEpoch 30/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9477 - auc: 0.9842 - val_loss: 0.1864 - val_accuracy: 0.9293 - val_auc: 0.9732\nEpoch 31/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1472 - accuracy: 0.9491 - auc: 0.9861 - val_loss: 0.1776 - val_accuracy: 0.9347 - val_auc: 0.9753\nEpoch 32/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1461 - accuracy: 0.9508 - auc: 0.9860 - val_loss: 0.1769 - val_accuracy: 0.9327 - val_auc: 0.9753\nEpoch 33/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1413 - accuracy: 0.9532 - auc: 0.9871 - val_loss: 0.1866 - val_accuracy: 0.9244 - val_auc: 0.9756\nEpoch 34/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9515 - auc: 0.9866 - val_loss: 0.1811 - val_accuracy: 0.9308 - val_auc: 0.9771\nEpoch 35/100\n255/255 [==============================] - 1s 2ms/step - loss: 0.1353 - accuracy: 0.9553 - auc: 0.9880 - val_loss: 0.1951 - val_accuracy: 0.9151 - val_auc: 0.9777\n","output_type":"stream"}]},{"cell_type":"code","source":"#Result\nresults=model.evaluate(x_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:50:40.139133Z","iopub.execute_input":"2022-06-08T09:50:40.139604Z","iopub.status.idle":"2022-06-08T09:50:40.456261Z","shell.execute_reply.started":"2022-06-08T09:50:40.139568Z","shell.execute_reply":"2022-06-08T09:50:40.455120Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"137/137 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9304 - auc: 0.9761\n","output_type":"stream"}]},{"cell_type":"code","source":"#printing the results\nprint('Test Accuracy:{:.2f}'.format(results[1]))\nprint('Test AIC:{:4f}'.format(results[0]))","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:55:40.264205Z","iopub.execute_input":"2022-06-08T09:55:40.264630Z","iopub.status.idle":"2022-06-08T09:55:40.270686Z","shell.execute_reply.started":"2022-06-08T09:55:40.264595Z","shell.execute_reply":"2022-06-08T09:55:40.269737Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Test Accuracy:0.93\nTest AIC:0.184153\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}