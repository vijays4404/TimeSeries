{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing library\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-27T03:40:38.664670Z","iopub.execute_input":"2022-01-27T03:40:38.665441Z","iopub.status.idle":"2022-01-27T03:40:38.670384Z","shell.execute_reply.started":"2022-01-27T03:40:38.665370Z","shell.execute_reply":"2022-01-27T03:40:38.669718Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#loading the data with list\ndfs=[pd.read_csv('../input/heartbeat/ptbdb_'+x+'.csv') for x in ['normal','abnormal']]","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:40:41.959171Z","iopub.execute_input":"2022-01-27T03:40:41.959469Z","iopub.status.idle":"2022-01-27T03:40:42.807055Z","shell.execute_reply.started":"2022-01-27T03:40:41.959437Z","shell.execute_reply":"2022-01-27T03:40:42.806348Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"for df in dfs:\n    df.columns=list(range(len(df.columns)))","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:40:45.353554Z","iopub.execute_input":"2022-01-27T03:40:45.354028Z","iopub.status.idle":"2022-01-27T03:40:45.360189Z","shell.execute_reply.started":"2022-01-27T03:40:45.353968Z","shell.execute_reply":"2022-01-27T03:40:45.359383Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#concating the column\ndf=pd.concat(dfs,axis=0).sample(frac=1,random_state=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:40:48.019049Z","iopub.execute_input":"2022-01-27T03:40:48.019395Z","iopub.status.idle":"2022-01-27T03:40:48.046851Z","shell.execute_reply.started":"2022-01-27T03:40:48.019364Z","shell.execute_reply":"2022-01-27T03:40:48.046127Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:40:53.338859Z","iopub.execute_input":"2022-01-27T03:40:53.339424Z","iopub.status.idle":"2022-01-27T03:40:53.377369Z","shell.execute_reply.started":"2022-01-27T03:40:53.339387Z","shell.execute_reply":"2022-01-27T03:40:53.376767Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"            0         1         2         3         4         5         6    \\\n0      1.000000  0.887073  0.774146  0.713224  0.682021  0.699851  0.595840   \n1      1.000000  0.684376  0.395907  0.288863  0.262102  0.231405  0.234160   \n2      1.000000  0.645543  0.270195  0.089833  0.038997  0.064067  0.045265   \n3      0.995881  0.993821  0.959835  0.872297  0.542739  0.054583  0.000000   \n4      0.996020  0.323383  0.109453  0.035821  0.264677  0.342289  0.367164   \n...         ...       ...       ...       ...       ...       ...       ...   \n14545  1.000000  0.979786  0.621879  0.146849  0.000000  0.266944  0.356718   \n14546  1.000000  0.648015  0.424677  0.315160  0.223816  0.156384  0.156863   \n14547  0.931217  1.000000  0.465201  0.150183  0.035409  0.033374  0.049247   \n14548  1.000000  0.588291  0.120570  0.056962  0.136076  0.181646  0.182595   \n14549  0.946429  0.315668  0.063940  0.011521  0.067972  0.151498  0.273618   \n\n            7         8         9    ...  178  179  180  181  182  183  184  \\\n0      0.552749  0.469539  0.481426  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1      0.218811  0.207399  0.212121  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2      0.062674  0.059192  0.057799  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3      0.098867  0.156540  0.302781  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4      0.402985  0.401990  0.420896  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n14545  0.421522  0.450059  0.457788  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14546  0.122908  0.093735  0.122908  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14547  0.070818  0.078958  0.087505  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14548  0.185759  0.178481  0.186076  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14549  0.391705  0.397465  0.425115  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n       185  186  187  \n0      0.0  0.0  1.0  \n1      0.0  0.0  1.0  \n2      0.0  0.0  1.0  \n3      0.0  0.0  1.0  \n4      0.0  0.0  1.0  \n...    ...  ...  ...  \n14545  0.0  0.0  0.0  \n14546  0.0  0.0  1.0  \n14547  0.0  0.0  1.0  \n14548  0.0  0.0  0.0  \n14549  0.0  0.0  1.0  \n\n[14550 rows x 188 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>178</th>\n      <th>179</th>\n      <th>180</th>\n      <th>181</th>\n      <th>182</th>\n      <th>183</th>\n      <th>184</th>\n      <th>185</th>\n      <th>186</th>\n      <th>187</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>0.887073</td>\n      <td>0.774146</td>\n      <td>0.713224</td>\n      <td>0.682021</td>\n      <td>0.699851</td>\n      <td>0.595840</td>\n      <td>0.552749</td>\n      <td>0.469539</td>\n      <td>0.481426</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>0.684376</td>\n      <td>0.395907</td>\n      <td>0.288863</td>\n      <td>0.262102</td>\n      <td>0.231405</td>\n      <td>0.234160</td>\n      <td>0.218811</td>\n      <td>0.207399</td>\n      <td>0.212121</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>0.645543</td>\n      <td>0.270195</td>\n      <td>0.089833</td>\n      <td>0.038997</td>\n      <td>0.064067</td>\n      <td>0.045265</td>\n      <td>0.062674</td>\n      <td>0.059192</td>\n      <td>0.057799</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.995881</td>\n      <td>0.993821</td>\n      <td>0.959835</td>\n      <td>0.872297</td>\n      <td>0.542739</td>\n      <td>0.054583</td>\n      <td>0.000000</td>\n      <td>0.098867</td>\n      <td>0.156540</td>\n      <td>0.302781</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.996020</td>\n      <td>0.323383</td>\n      <td>0.109453</td>\n      <td>0.035821</td>\n      <td>0.264677</td>\n      <td>0.342289</td>\n      <td>0.367164</td>\n      <td>0.402985</td>\n      <td>0.401990</td>\n      <td>0.420896</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14545</th>\n      <td>1.000000</td>\n      <td>0.979786</td>\n      <td>0.621879</td>\n      <td>0.146849</td>\n      <td>0.000000</td>\n      <td>0.266944</td>\n      <td>0.356718</td>\n      <td>0.421522</td>\n      <td>0.450059</td>\n      <td>0.457788</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14546</th>\n      <td>1.000000</td>\n      <td>0.648015</td>\n      <td>0.424677</td>\n      <td>0.315160</td>\n      <td>0.223816</td>\n      <td>0.156384</td>\n      <td>0.156863</td>\n      <td>0.122908</td>\n      <td>0.093735</td>\n      <td>0.122908</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14547</th>\n      <td>0.931217</td>\n      <td>1.000000</td>\n      <td>0.465201</td>\n      <td>0.150183</td>\n      <td>0.035409</td>\n      <td>0.033374</td>\n      <td>0.049247</td>\n      <td>0.070818</td>\n      <td>0.078958</td>\n      <td>0.087505</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14548</th>\n      <td>1.000000</td>\n      <td>0.588291</td>\n      <td>0.120570</td>\n      <td>0.056962</td>\n      <td>0.136076</td>\n      <td>0.181646</td>\n      <td>0.182595</td>\n      <td>0.185759</td>\n      <td>0.178481</td>\n      <td>0.186076</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14549</th>\n      <td>0.946429</td>\n      <td>0.315668</td>\n      <td>0.063940</td>\n      <td>0.011521</td>\n      <td>0.067972</td>\n      <td>0.151498</td>\n      <td>0.273618</td>\n      <td>0.391705</td>\n      <td>0.397465</td>\n      <td>0.425115</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>14550 rows × 188 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#renaming the column\ndf=df.rename({187:'Label'},axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:42:14.035113Z","iopub.execute_input":"2022-01-27T03:42:14.035712Z","iopub.status.idle":"2022-01-27T03:42:14.051041Z","shell.execute_reply.started":"2022-01-27T03:42:14.035660Z","shell.execute_reply":"2022-01-27T03:42:14.050331Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:42:18.333063Z","iopub.execute_input":"2022-01-27T03:42:18.333348Z","iopub.status.idle":"2022-01-27T03:42:18.371858Z","shell.execute_reply.started":"2022-01-27T03:42:18.333321Z","shell.execute_reply":"2022-01-27T03:42:18.371168Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"              0         1         2         3         4         5         6  \\\n0      1.000000  0.887073  0.774146  0.713224  0.682021  0.699851  0.595840   \n1      1.000000  0.684376  0.395907  0.288863  0.262102  0.231405  0.234160   \n2      1.000000  0.645543  0.270195  0.089833  0.038997  0.064067  0.045265   \n3      0.995881  0.993821  0.959835  0.872297  0.542739  0.054583  0.000000   \n4      0.996020  0.323383  0.109453  0.035821  0.264677  0.342289  0.367164   \n...         ...       ...       ...       ...       ...       ...       ...   \n14545  1.000000  0.979786  0.621879  0.146849  0.000000  0.266944  0.356718   \n14546  1.000000  0.648015  0.424677  0.315160  0.223816  0.156384  0.156863   \n14547  0.931217  1.000000  0.465201  0.150183  0.035409  0.033374  0.049247   \n14548  1.000000  0.588291  0.120570  0.056962  0.136076  0.181646  0.182595   \n14549  0.946429  0.315668  0.063940  0.011521  0.067972  0.151498  0.273618   \n\n              7         8         9  ...  178  179  180  181  182  183  184  \\\n0      0.552749  0.469539  0.481426  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1      0.218811  0.207399  0.212121  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2      0.062674  0.059192  0.057799  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3      0.098867  0.156540  0.302781  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4      0.402985  0.401990  0.420896  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n14545  0.421522  0.450059  0.457788  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14546  0.122908  0.093735  0.122908  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14547  0.070818  0.078958  0.087505  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14548  0.185759  0.178481  0.186076  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14549  0.391705  0.397465  0.425115  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n       185  186  Label  \n0      0.0  0.0    1.0  \n1      0.0  0.0    1.0  \n2      0.0  0.0    1.0  \n3      0.0  0.0    1.0  \n4      0.0  0.0    1.0  \n...    ...  ...    ...  \n14545  0.0  0.0    0.0  \n14546  0.0  0.0    1.0  \n14547  0.0  0.0    1.0  \n14548  0.0  0.0    0.0  \n14549  0.0  0.0    1.0  \n\n[14550 rows x 188 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>178</th>\n      <th>179</th>\n      <th>180</th>\n      <th>181</th>\n      <th>182</th>\n      <th>183</th>\n      <th>184</th>\n      <th>185</th>\n      <th>186</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>0.887073</td>\n      <td>0.774146</td>\n      <td>0.713224</td>\n      <td>0.682021</td>\n      <td>0.699851</td>\n      <td>0.595840</td>\n      <td>0.552749</td>\n      <td>0.469539</td>\n      <td>0.481426</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>0.684376</td>\n      <td>0.395907</td>\n      <td>0.288863</td>\n      <td>0.262102</td>\n      <td>0.231405</td>\n      <td>0.234160</td>\n      <td>0.218811</td>\n      <td>0.207399</td>\n      <td>0.212121</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>0.645543</td>\n      <td>0.270195</td>\n      <td>0.089833</td>\n      <td>0.038997</td>\n      <td>0.064067</td>\n      <td>0.045265</td>\n      <td>0.062674</td>\n      <td>0.059192</td>\n      <td>0.057799</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.995881</td>\n      <td>0.993821</td>\n      <td>0.959835</td>\n      <td>0.872297</td>\n      <td>0.542739</td>\n      <td>0.054583</td>\n      <td>0.000000</td>\n      <td>0.098867</td>\n      <td>0.156540</td>\n      <td>0.302781</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.996020</td>\n      <td>0.323383</td>\n      <td>0.109453</td>\n      <td>0.035821</td>\n      <td>0.264677</td>\n      <td>0.342289</td>\n      <td>0.367164</td>\n      <td>0.402985</td>\n      <td>0.401990</td>\n      <td>0.420896</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14545</th>\n      <td>1.000000</td>\n      <td>0.979786</td>\n      <td>0.621879</td>\n      <td>0.146849</td>\n      <td>0.000000</td>\n      <td>0.266944</td>\n      <td>0.356718</td>\n      <td>0.421522</td>\n      <td>0.450059</td>\n      <td>0.457788</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14546</th>\n      <td>1.000000</td>\n      <td>0.648015</td>\n      <td>0.424677</td>\n      <td>0.315160</td>\n      <td>0.223816</td>\n      <td>0.156384</td>\n      <td>0.156863</td>\n      <td>0.122908</td>\n      <td>0.093735</td>\n      <td>0.122908</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14547</th>\n      <td>0.931217</td>\n      <td>1.000000</td>\n      <td>0.465201</td>\n      <td>0.150183</td>\n      <td>0.035409</td>\n      <td>0.033374</td>\n      <td>0.049247</td>\n      <td>0.070818</td>\n      <td>0.078958</td>\n      <td>0.087505</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14548</th>\n      <td>1.000000</td>\n      <td>0.588291</td>\n      <td>0.120570</td>\n      <td>0.056962</td>\n      <td>0.136076</td>\n      <td>0.181646</td>\n      <td>0.182595</td>\n      <td>0.185759</td>\n      <td>0.178481</td>\n      <td>0.186076</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14549</th>\n      <td>0.946429</td>\n      <td>0.315668</td>\n      <td>0.063940</td>\n      <td>0.011521</td>\n      <td>0.067972</td>\n      <td>0.151498</td>\n      <td>0.273618</td>\n      <td>0.391705</td>\n      <td>0.397465</td>\n      <td>0.425115</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>14550 rows × 188 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#creating target and input column and storing it into x and y variable","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:43:46.743357Z","iopub.execute_input":"2022-01-27T03:43:46.744144Z","iopub.status.idle":"2022-01-27T03:43:46.747398Z","shell.execute_reply.started":"2022-01-27T03:43:46.744106Z","shell.execute_reply":"2022-01-27T03:43:46.746718Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"y=df['Label'].copy()\nx=df.drop('Label',axis=1).copy()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:44:06.960113Z","iopub.execute_input":"2022-01-27T03:44:06.960424Z","iopub.status.idle":"2022-01-27T03:44:06.986366Z","shell.execute_reply.started":"2022-01-27T03:44:06.960392Z","shell.execute_reply":"2022-01-27T03:44:06.985526Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#spliting the data between train and test \nx_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.7,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:45:09.669782Z","iopub.execute_input":"2022-01-27T03:45:09.670540Z","iopub.status.idle":"2022-01-27T03:45:09.692893Z","shell.execute_reply.started":"2022-01-27T03:45:09.670501Z","shell.execute_reply":"2022-01-27T03:45:09.691925Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#getting the information about the dataset\nx_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:45:19.944156Z","iopub.execute_input":"2022-01-27T03:45:19.944425Z","iopub.status.idle":"2022-01-27T03:45:19.949861Z","shell.execute_reply.started":"2022-01-27T03:45:19.944398Z","shell.execute_reply":"2022-01-27T03:45:19.948976Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(10185, 187)"},"metadata":{}}]},{"cell_type":"code","source":"x_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:45:26.028496Z","iopub.execute_input":"2022-01-27T03:45:26.028969Z","iopub.status.idle":"2022-01-27T03:45:26.035787Z","shell.execute_reply.started":"2022-01-27T03:45:26.028916Z","shell.execute_reply":"2022-01-27T03:45:26.034871Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"(4365, 187)"},"metadata":{}}]},{"cell_type":"code","source":"#training the data\n#this is the input layer in which we specified the shape of the column from the training set \ninputs=tf.keras.Input(shape=(x_train.shape[1],))\n#This is the first hidden layer in which 64 points and it get input from first layer which is input layer\nx=tf.keras.layers.Dense(64,activation='relu')(inputs)\n#This is the second hideen layer in which same 64 points as with first layer and it get input from first layer which  we stored in x\nx=tf.keras.layers.Dense(64,activation='relu')(x)\n#here 1 means we will get output of only  one value whether 0 or 1 and sigmoid activated  which mean it has values  between 0 and 1\noutputs=tf.keras.layers.Dense(1,activation='sigmoid')(x)\n\n\n#Now training the model\nmodel=tf.keras.Model(inputs=inputs,outputs=outputs)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-27T03:55:18.455627Z","iopub.execute_input":"2022-01-27T03:55:18.455938Z","iopub.status.idle":"2022-01-27T03:55:19.682695Z","shell.execute_reply.started":"2022-01-27T03:55:18.455909Z","shell.execute_reply":"2022-01-27T03:55:19.682117Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"\nUser settings:\n\n   KMP_AFFINITY=granularity=fine,noverbose,compact,1,0\n   KMP_BLOCKTIME=0\n   KMP_DUPLICATE_LIB_OK=True\n   KMP_INIT_AT_FORK=FALSE\n   KMP_SETTINGS=1\n   KMP_WARNINGS=0\n\nEffective settings:\n\n   KMP_ABORT_DELAY=0\n   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n   KMP_ALIGN_ALLOC=64\n   KMP_ALL_THREADPRIVATE=128\n   KMP_ATOMIC_MODE=2\n   KMP_BLOCKTIME=0\n   KMP_CPUINFO_FILE: value is not defined\n   KMP_DETERMINISTIC_REDUCTION=false\n   KMP_DEVICE_THREAD_LIMIT=2147483647\n   KMP_DISP_NUM_BUFFERS=7\n   KMP_DUPLICATE_LIB_OK=true\n   KMP_ENABLE_TASK_THROTTLING=true\n   KMP_FORCE_REDUCTION: value is not defined\n   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n   KMP_FORKJOIN_BARRIER='2,2'\n   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n   KMP_GTID_MODE=3\n   KMP_HANDLE_SIGNALS=false\n   KMP_HOT_TEAMS_MAX_LEVEL=1\n   KMP_HOT_TEAMS_MODE=0\n   KMP_INIT_AT_FORK=true\n   KMP_LIBRARY=throughput\n   KMP_LOCK_KIND=queuing\n   KMP_MALLOC_POOL_INCR=1M\n   KMP_NUM_LOCKS_IN_BLOCK=1\n   KMP_PLAIN_BARRIER='2,2'\n   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n   KMP_REDUCTION_BARRIER='1,1'\n   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n   KMP_SCHEDULE='static,balanced;guided,iterative'\n   KMP_SETTINGS=true\n   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n   KMP_STACKOFFSET=64\n   KMP_STACKPAD=0\n   KMP_STACKSIZE=8M\n   KMP_STORAGE_MAP=false\n   KMP_TASKING=2\n   KMP_TASKLOOP_MIN_TASKS=0\n   KMP_TASK_STEALING_CONSTRAINT=1\n   KMP_TEAMS_THREAD_LIMIT=4\n   KMP_TOPOLOGY_METHOD=all\n   KMP_USE_YIELD=1\n   KMP_VERSION=false\n   KMP_WARNINGS=false\n   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n   OMP_ALLOCATOR=omp_default_mem_alloc\n   OMP_CANCELLATION=false\n   OMP_DEFAULT_DEVICE=0\n   OMP_DISPLAY_AFFINITY=false\n   OMP_DISPLAY_ENV=false\n   OMP_DYNAMIC=false\n   OMP_MAX_ACTIVE_LEVELS=1\n   OMP_MAX_TASK_PRIORITY=0\n   OMP_NESTED: deprecated; max-active-levels-var=1\n   OMP_NUM_THREADS: value is not defined\n   OMP_PLACES: value is not defined\n   OMP_PROC_BIND='intel'\n   OMP_SCHEDULE='static'\n   OMP_STACKSIZE=8M\n   OMP_TARGET_OFFLOAD=DEFAULT\n   OMP_THREAD_LIMIT=2147483647\n   OMP_WAIT_POLICY=PASSIVE\n   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'\n\n2022-01-27 03:55:19.613689: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    #this loss function uses for binary classification\n    loss='binary_crossentropy',\n    #metrics is uses to get the accuracy score\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.AUC(name='auc')\n    ])\n# we will store the result in history\nhistory=model.fit(x_train,y_train,validation_split=0.2,\n                 batch_size=32,\n                 epochs=100,\n                 callbacks=[\n                     tf.keras.callbacks.EarlyStopping(\n                     monitor='val_loss',\n                     patience=3,\n                     restore_best_weights=True)\n                 ])","metadata":{"execution":{"iopub.status.busy":"2022-01-27T04:01:25.660002Z","iopub.execute_input":"2022-01-27T04:01:25.660355Z","iopub.status.idle":"2022-01-27T04:01:43.970473Z","shell.execute_reply.started":"2022-01-27T04:01:25.660322Z","shell.execute_reply":"2022-01-27T04:01:43.969433Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"2022-01-27 04:01:25.815436: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n255/255 [==============================] - 2s 5ms/step - loss: 0.4454 - accuracy: 0.7833 - auc: 0.8270 - val_loss: 0.3723 - val_accuracy: 0.8184 - val_auc: 0.8873\nEpoch 2/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.3601 - accuracy: 0.8310 - auc: 0.8960 - val_loss: 0.3315 - val_accuracy: 0.8478 - val_auc: 0.9107\nEpoch 3/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.3219 - accuracy: 0.8601 - auc: 0.9193 - val_loss: 0.3145 - val_accuracy: 0.8513 - val_auc: 0.9252\nEpoch 4/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.2901 - accuracy: 0.8789 - auc: 0.9354 - val_loss: 0.2679 - val_accuracy: 0.8905 - val_auc: 0.9451\nEpoch 5/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.2600 - accuracy: 0.8941 - auc: 0.9490 - val_loss: 0.2568 - val_accuracy: 0.8910 - val_auc: 0.9501\nEpoch 6/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.8986 - auc: 0.9568 - val_loss: 0.2324 - val_accuracy: 0.9087 - val_auc: 0.9575\nEpoch 7/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.2131 - accuracy: 0.9175 - auc: 0.9660 - val_loss: 0.2214 - val_accuracy: 0.9097 - val_auc: 0.9624\nEpoch 8/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1970 - accuracy: 0.9192 - auc: 0.9713 - val_loss: 0.2055 - val_accuracy: 0.9180 - val_auc: 0.9699\nEpoch 9/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1827 - accuracy: 0.9275 - auc: 0.9750 - val_loss: 0.2098 - val_accuracy: 0.9121 - val_auc: 0.9688\nEpoch 10/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1712 - accuracy: 0.9352 - auc: 0.9782 - val_loss: 0.1894 - val_accuracy: 0.9273 - val_auc: 0.9720\nEpoch 11/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1615 - accuracy: 0.9395 - auc: 0.9805 - val_loss: 0.1822 - val_accuracy: 0.9219 - val_auc: 0.9748\nEpoch 12/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1549 - accuracy: 0.9388 - auc: 0.9817 - val_loss: 0.2055 - val_accuracy: 0.9092 - val_auc: 0.9772\nEpoch 13/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1388 - accuracy: 0.9473 - auc: 0.9853 - val_loss: 0.1666 - val_accuracy: 0.9386 - val_auc: 0.9760\nEpoch 14/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1288 - accuracy: 0.9491 - auc: 0.9876 - val_loss: 0.2049 - val_accuracy: 0.9259 - val_auc: 0.9734\nEpoch 15/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1270 - accuracy: 0.9542 - auc: 0.9878 - val_loss: 0.1662 - val_accuracy: 0.9308 - val_auc: 0.9783\nEpoch 16/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1207 - accuracy: 0.9563 - auc: 0.9887 - val_loss: 0.1461 - val_accuracy: 0.9401 - val_auc: 0.9809\nEpoch 17/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1125 - accuracy: 0.9575 - auc: 0.9902 - val_loss: 0.1752 - val_accuracy: 0.9337 - val_auc: 0.9796\nEpoch 18/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1038 - accuracy: 0.9637 - auc: 0.9917 - val_loss: 0.1525 - val_accuracy: 0.9362 - val_auc: 0.9815\nEpoch 19/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.1039 - accuracy: 0.9606 - auc: 0.9917 - val_loss: 0.1355 - val_accuracy: 0.9494 - val_auc: 0.9840\nEpoch 20/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9669 - auc: 0.9931 - val_loss: 0.1480 - val_accuracy: 0.9352 - val_auc: 0.9834\nEpoch 21/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9640 - auc: 0.9927 - val_loss: 0.1450 - val_accuracy: 0.9460 - val_auc: 0.9816\nEpoch 22/100\n255/255 [==============================] - 1s 3ms/step - loss: 0.0892 - accuracy: 0.9643 - auc: 0.9941 - val_loss: 0.1365 - val_accuracy: 0.9470 - val_auc: 0.9842\n","output_type":"stream"}]},{"cell_type":"code","source":"#evaluating the accuracy of model\nresults=model.evaluate(x_test,y_test,verbose=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T04:05:20.916273Z","iopub.execute_input":"2022-01-27T04:05:20.917247Z","iopub.status.idle":"2022-01-27T04:05:21.210268Z","shell.execute_reply.started":"2022-01-27T04:05:20.917189Z","shell.execute_reply":"2022-01-27T04:05:21.209190Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"#printing the model\nprint('Test Accuracy:{:2f}%'.format(results[1]*100))\nprint('Test Auc:{:4f}'.format(results[2]))","metadata":{"execution":{"iopub.status.busy":"2022-01-27T04:06:42.621059Z","iopub.execute_input":"2022-01-27T04:06:42.621401Z","iopub.status.idle":"2022-01-27T04:06:42.627816Z","shell.execute_reply.started":"2022-01-27T04:06:42.621369Z","shell.execute_reply":"2022-01-27T04:06:42.626934Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Test Accuracy:94.570446%\nTest Auc:0.984528\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}