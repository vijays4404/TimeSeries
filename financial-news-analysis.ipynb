{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Financial News Sentiment Prediction","metadata":{}},{"cell_type":"markdown","source":"Natural Language Processing (NLP) involves a set of techniques and methodologies used to enable computers to understand, interpret, and generate human language. Here is a general process for NLP:\n\nText Collection: The first step is to gather the data that will be used for NLP. This can be done by scraping websites, using existing datasets, or generating synthetic data.\n\nText Preprocessing: The collected text data must be cleaned, normalized, and transformed into a format that can be used by NLP algorithms. This process includes tasks such as tokenization (splitting text into words or phrases), part-of-speech tagging (assigning grammatical labels to words), and stemming or lemmatization (reducing words to their root form).\n\nFeature Extraction: Next, the most relevant features must be extracted from the preprocessed text. This could include features like word frequency, n-grams (sequences of n words), or word embeddings (dense vector representations of words).\n\nModel Training: Once the features are extracted, a machine learning model is trained on the data. Depending on the task, different types of models can be used, such as supervised learning models (e.g., classification) or unsupervised learning models (e.g., clustering).\n\nModel Evaluation: The performance of the model is evaluated using metrics such as accuracy, precision, recall, and F1 score. This step helps to identify the strengths and weaknesses of the model and can guide further improvements.\n\nModel Deployment: After the model is trained and evaluated, it can be deployed to a production environment for use in applications such as chatbots, sentiment analysis, or text classification.\n\nModel Maintenance: The NLP system must be continually monitored and updated to ensure that it remains accurate and effective. This may involve retraining the model on new data or making changes to the preprocessing or feature extraction steps.\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Importing the library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n#Tokenizer\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n#pad_sequences\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n#train_test_split\nfrom sklearn.model_selection import train_test_split\n#neural_network\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-02-25T04:26:18.605008Z","iopub.execute_input":"2023-02-25T04:26:18.605721Z","iopub.status.idle":"2023-02-25T04:26:18.612527Z","shell.execute_reply.started":"2023-02-25T04:26:18.605680Z","shell.execute_reply":"2023-02-25T04:26:18.610271Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"# loading the dataset","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/sentiment-analysis-for-financial-news/all-data.csv',names=['Label','Text'],encoding='latin-1')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-02-25T04:26:18.615250Z","iopub.execute_input":"2023-02-25T04:26:18.615715Z","iopub.status.idle":"2023-02-25T04:26:18.650729Z","shell.execute_reply.started":"2023-02-25T04:26:18.615677Z","shell.execute_reply":"2023-02-25T04:26:18.649468Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"         Label                                               Text\n0      neutral  According to Gran , the company has no plans t...\n1      neutral  Technopolis plans to develop in stages an area...\n2     negative  The international electronic industry company ...\n3     positive  With the new production plant the company woul...\n4     positive  According to the company 's updated strategy f...\n...        ...                                                ...\n4841  negative  LONDON MarketWatch -- Share prices ended lower...\n4842   neutral  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n4843  negative  Operating profit fell to EUR 35.4 mn from EUR ...\n4844  negative  Net sales of the Paper segment decreased to EU...\n4845  negative  Sales in Finland decreased by 10.5 % in Januar...\n\n[4846 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neutral</td>\n      <td>According to Gran , the company has no plans t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neutral</td>\n      <td>Technopolis plans to develop in stages an area...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>negative</td>\n      <td>The international electronic industry company ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>positive</td>\n      <td>With the new production plant the company woul...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>positive</td>\n      <td>According to the company 's updated strategy f...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4841</th>\n      <td>negative</td>\n      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n    </tr>\n    <tr>\n      <th>4842</th>\n      <td>neutral</td>\n      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n    </tr>\n    <tr>\n      <th>4843</th>\n      <td>negative</td>\n      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n    </tr>\n    <tr>\n      <th>4844</th>\n      <td>negative</td>\n      <td>Net sales of the Paper segment decreased to EU...</td>\n    </tr>\n    <tr>\n      <th>4845</th>\n      <td>negative</td>\n      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n    </tr>\n  </tbody>\n</table>\n<p>4846 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Getting Preliminary Information","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-02-25T04:26:18.652114Z","iopub.execute_input":"2023-02-25T04:26:18.653047Z","iopub.status.idle":"2023-02-25T04:26:18.666817Z","shell.execute_reply.started":"2023-02-25T04:26:18.653010Z","shell.execute_reply":"2023-02-25T04:26:18.665210Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4846 entries, 0 to 4845\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   Label   4846 non-null   object\n 1   Text    4846 non-null   object\ndtypes: object(2)\nmemory usage: 75.8+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def get_sequences(texts):\n    #creating the tokenizer object\n    tokenizer=Tokenizer()\n    #applying function called fit_on_texts on objects\n    tokenizer.fit_on_texts(texts)\n    #giving each word number \n    sequences=tokenizer.texts_to_sequences(texts)\n    #returning sequences\n    max_seq_length=np.max(list(map(lambda x:len(x),sequences)))\n    sequences=pad_sequences(sequences,maxlen=max_seq_length,padding='post')\n    return sequences","metadata":{"execution":{"iopub.status.busy":"2023-02-25T04:26:18.669963Z","iopub.execute_input":"2023-02-25T04:26:18.670565Z","iopub.status.idle":"2023-02-25T04:26:18.677277Z","shell.execute_reply.started":"2023-02-25T04:26:18.670526Z","shell.execute_reply":"2023-02-25T04:26:18.676075Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"sequences=get_sequences(df['Text'])\nsequences","metadata":{"execution":{"iopub.status.busy":"2023-02-25T04:26:18.679260Z","iopub.execute_input":"2023-02-25T04:26:18.679953Z","iopub.status.idle":"2023-02-25T04:26:18.931615Z","shell.execute_reply.started":"2023-02-25T04:26:18.679902Z","shell.execute_reply":"2023-02-25T04:26:18.930757Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"array([[  94,    5, 3498, ...,    0,    0,    0],\n       [ 840,  336,    5, ...,    0,    0,    0],\n       [   1,  293,  656, ...,    0,    0,    0],\n       ...,\n       [  42,   31,  242, ...,    0,    0,    0],\n       [  30,   27,    2, ...,    0,    0,    0],\n       [  27,    3,   35, ...,    0,    0,    0]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_inputs(df):\n    df=df.copy()\n    sequences=get_sequences(df['Text'])\n    label_mapping={'negative':0,\n                  'neutral':1,\n                  'positive':2}\n    y=df['Label']=df['Label'].replace(label_mapping)\n    sequences_train,sequences_test,y_train,y_test=train_test_split(sequences,y,train_size=0.7)\n    return sequences_train,sequences_test,y_train,y_test","metadata":{"execution":{"iopub.status.busy":"2023-02-25T04:26:18.932774Z","iopub.execute_input":"2023-02-25T04:26:18.933227Z","iopub.status.idle":"2023-02-25T04:26:18.938925Z","shell.execute_reply.started":"2023-02-25T04:26:18.933195Z","shell.execute_reply":"2023-02-25T04:26:18.937482Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"sequences_train,sequences_test,y_train,y_test=preprocess_inputs(df)\nprint(sequences_train.shape)\nprint(sequences_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-25T04:26:18.941372Z","iopub.execute_input":"2023-02-25T04:26:18.941730Z","iopub.status.idle":"2023-02-25T04:26:19.212117Z","shell.execute_reply.started":"2023-02-25T04:26:18.941694Z","shell.execute_reply":"2023-02-25T04:26:19.210673Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"(3392, 71)\n(1454, 71)\n(3392,)\n(1454,)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What is TensorFlow\nTensorFlow is an open source software library developed by Google for building and training machine learning models. It provides a comprehensive set of tools for building and deploying machine learning models across a range of platforms, including desktops, mobile devices, and the cloud.\n\nAt its core, TensorFlow is a computational framework for building and executing numerical computations using data flow graphs. In a data flow graph, nodes represent mathematical operations, while edges represent the flow of data between these operations. TensorFlow provides a rich set of APIs for building these data flow graphs, as well as high-level APIs for building and training machine learning models.\n\nOne of the key features of TensorFlow is its support for building deep neural networks, which are a class of machine learning models that are particularly effective for tasks such as image recognition and natural language processing. TensorFlow provides a wide range of pre-built layers and models for building deep neural networks, as well as APIs for building custom layers and models.\n\nTensorFlow also provides a variety of tools for training machine learning models, including built-in optimizers for stochastic gradient descent and other optimization algorithms, as well as tools for monitoring training progress and visualizing results. It also supports distributed training across multiple machines or GPUs, which can significantly speed up training times for large models.\n\nIn addition to training models, TensorFlow also provides tools for deploying models in production environments. This includes support for exporting trained models to a variety of formats, as well as serving models using a variety of deployment targets, including mobile devices, web applications, and cloud services.\n\nAnother key feature of TensorFlow is its support for automatic differentiation, which is a technique for computing the gradient of a function with respect to its input parameters. This is particularly useful for training machine learning models, as it allows for efficient computation of gradients during the training process.\n\nFinally, TensorFlow also provides a variety of tools and APIs for working with data, including tools for reading and writing data in a variety of formats, as well as APIs for manipulating and transforming data.\n\nOverall, TensorFlow is a powerful and flexible tool for building and deploying machine learning models, with a rich set of APIs and tools for working with data, training models, and deploying models in production environments. Its support for deep neural networks and distributed training makes it particularly well-suited for building large-scale machine learning systems, and its open source nature and active community make it a popular choice for machine learning researchers and practitioners around the world.\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Training the Model","metadata":{}},{"cell_type":"code","source":"#This line defines the input layer for the model, with a shape of (sequences_train.shape[1],) which represents the length of the input sequences.\n\ninputs=tf.keras.Input(shape=(sequences_train.shape[1],))\n\n\n#This line adds an embedding layer to the model, which is used to convert each integer in the input sequences to a dense vector of fixed size. The input_dim parameter specifies the size of the vocabulary (i.e., the maximum integer index), output_dim specifies the size of the embedding vector, and input_length specifies the length of the input sequences.\n\n\nx=tf.keras.layers.Embedding(input_dim=10123,output_dim=128,\n                            input_length=sequences_train.shape[1]\n                           )(inputs)\n\n\n#This line adds a Gated Recurrent Unit (GRU) layer to the model, which is a type of recurrent neural network (RNN) that can model sequential data. The 256 parameter specifies the number of units in the GRU layer, and activation='tanh' specifies the activation function to use.\n\nx=tf.keras.layers.GRU(256,activation='tanh')(x)\n\n\n#This line adds a fully connected output layer to the model, which has 3 output nodes and uses a softmax activation function to produce a probability distribution over the output classes. The Dense function is used to create this layer.\n\n\noutputs=tf.keras.layers.Dense(3,activation='softmax')(x)\n#This line creates a tf.keras.Model object that encapsulates the input and output layers of the model.\nmodel=tf.keras.Model(inputs=inputs,outputs=outputs)\n#This line compiles the model, specifying the optimizer, loss function, and evaluation metrics to use during training. The Adam optimizer is used, along with sparse categorical cross-entropy loss and accuracy as the evaluation metric.\nmodel.compile(optimizer='adam',\n             loss='sparse_categorical_crossentropy',\n             metrics=['accuracy'])\n\n#This line trains the model on the training data, with a validation split of 0.2 (i.e., 20% of the data is used for validation). The batch_size and epochs parameters control the size of the mini-batches used during training and the number of epochs to train for, respectively. The callbacks parameter specifies a list of callbacks to use during training, in this case including an early stopping callback that will stop training if the validation loss does not improve for 3 epochs, and restore the best weights based on the validation loss. The history object returned by model.fit contains information about the training and validation loss and accuracy over each epoch.\n\n\nhistory=model.fit(sequences_train,\n                 y_train,validation_split=0.2,\n                 batch_size=32,\n                 epochs=100,\n                 callbacks=[\n                     tf.keras.callbacks.EarlyStopping(\n                     monitor='val_loss',\n                     patience=3,\n                         restore_best_weights=True)\n                 ])","metadata":{"execution":{"iopub.status.busy":"2023-02-25T04:30:18.464965Z","iopub.execute_input":"2023-02-25T04:30:18.465417Z","iopub.status.idle":"2023-02-25T04:31:39.404661Z","shell.execute_reply.started":"2023-02-25T04:30:18.465378Z","shell.execute_reply":"2023-02-25T04:31:39.403712Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Epoch 1/100\n85/85 [==============================] - 12s 118ms/step - loss: 0.9323 - accuracy: 0.6012 - val_loss: 0.9417 - val_accuracy: 0.5847\nEpoch 2/100\n85/85 [==============================] - 10s 114ms/step - loss: 0.9212 - accuracy: 0.6012 - val_loss: 0.9408 - val_accuracy: 0.5847\nEpoch 3/100\n85/85 [==============================] - 10s 116ms/step - loss: 0.9221 - accuracy: 0.6012 - val_loss: 0.9374 - val_accuracy: 0.5847\nEpoch 4/100\n85/85 [==============================] - 10s 114ms/step - loss: 0.9215 - accuracy: 0.6012 - val_loss: 0.9405 - val_accuracy: 0.5847\nEpoch 5/100\n85/85 [==============================] - 10s 116ms/step - loss: 0.9216 - accuracy: 0.6012 - val_loss: 0.9366 - val_accuracy: 0.5847\nEpoch 6/100\n85/85 [==============================] - 10s 115ms/step - loss: 0.9206 - accuracy: 0.6012 - val_loss: 0.9367 - val_accuracy: 0.5847\nEpoch 7/100\n85/85 [==============================] - 10s 114ms/step - loss: 0.9213 - accuracy: 0.6012 - val_loss: 0.9470 - val_accuracy: 0.5847\nEpoch 8/100\n85/85 [==============================] - 10s 115ms/step - loss: 0.9213 - accuracy: 0.6012 - val_loss: 0.9391 - val_accuracy: 0.5847\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(sequences_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2023-02-25T04:34:18.029572Z","iopub.execute_input":"2023-02-25T04:34:18.029977Z","iopub.status.idle":"2023-02-25T04:34:19.896078Z","shell.execute_reply.started":"2023-02-25T04:34:18.029937Z","shell.execute_reply":"2023-02-25T04:34:19.894944Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"46/46 [==============================] - 2s 39ms/step - loss: 0.9369 - accuracy: 0.5853\n","output_type":"stream"},{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"[0.9368535280227661, 0.5852819681167603]"},"metadata":{}}]},{"cell_type":"code","source":"model.predict(sequences_test)","metadata":{"execution":{"iopub.status.busy":"2023-02-25T04:34:43.704440Z","iopub.execute_input":"2023-02-25T04:34:43.705680Z","iopub.status.idle":"2023-02-25T04:34:45.798757Z","shell.execute_reply.started":"2023-02-25T04:34:43.705635Z","shell.execute_reply":"2023-02-25T04:34:45.797349Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"46/46 [==============================] - 2s 35ms/step\n","output_type":"stream"},{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"array([[0.13867693, 0.5603542 , 0.30096886],\n       [0.13867693, 0.5603542 , 0.3009689 ],\n       [0.13867694, 0.5603542 , 0.3009689 ],\n       ...,\n       [0.13867694, 0.56035423, 0.3009689 ],\n       [0.13867696, 0.56035423, 0.3009689 ],\n       [0.13867696, 0.56035423, 0.3009689 ]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"df.iloc[0,:]","metadata":{"execution":{"iopub.status.busy":"2023-02-25T04:26:19.474101Z","iopub.status.idle":"2023-02-25T04:26:19.474478Z","shell.execute_reply.started":"2023-02-25T04:26:19.474286Z","shell.execute_reply":"2023-02-25T04:26:19.474320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}