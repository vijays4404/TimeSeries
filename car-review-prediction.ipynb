{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1837939,"sourceType":"datasetVersion","datasetId":1033786}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing library\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nfrom nltk.corpus import stopwords\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom sklearn.metrics import r2_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#loading the dataset\ndf=pd.read_csv('/kaggle/input/edmunds-car-review/Review.csv')\ndf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#getting preliminary information about the dataset\ndf.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_texts(texts):\n    texts=texts.copy()\n    #creating a list of most commonly used word in english\n    stop_words=stopwords.words('english')\n    #replacing any \\ with empty and number with empty string\n    texts=texts.apply(lambda x:re.sub(r'\\\\n','',x))\n    texts=texts.apply(lambda x:re.sub(r'\\d+','',x))\n    #removing stop_word from the sentences\n    texts=texts.apply(lambda x:\" \".join([word for word in x.split() if word.lower() not in stop_words]))\n\n    return texts\n\n\ndef get_sequences(texts):\n    tokenizer=Tokenizer(num_words=50000)\n    tokenizer.fit_on_texts(texts)\n    sequences=tokenizer.texts_to_sequences(texts)\n    max_sequence_length=np.max(list(map(lambda x:len(x),sequences)))\n    print('The maximum sequence length',max_sequence_length)\n    \n    sequences=pad_sequences(sequences,maxlen=max_sequence_length,padding='post')\n    return sequences\n\n\ndef encode_date(df,column):\n    df=df.copy()\n    df[column]=pd.to_datetime(df[column],errors='coerce')\n    df['ReviewYear']=df[column].apply(lambda x:x.year)\n    df['ReviewMonth']=df[column].apply(lambda x:x.month)\n    df['ReviewDay']=df[column].apply(lambda x:x.day)\n    df=df.drop(column,axis=1)\n    return df\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def onehot_encode(df,columns):\n    df=df.copy()\n    for column in columns:\n        dummies=pd.get_dummies(df[column],prefix=column)\n        df=pd.concat([df,dummies],axis=1)\n        df=df.drop(column,axis=1)\n        for column in df.columns:\n            if df[column].dtypes=='bool':\n                df[column]=df[column].astype(int)\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"get_sequences(x['Review'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Date']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_inputs(df):\n    #creating the copy of the dataset\n    df=df.copy()\n    #dropping the Reviewer column \n    df=df.drop('Reviewer',axis=1)\n    df=df.drop(df.loc[df['Review'].isna(),:].index,axis=0).reset_index(drop=True)\n    \n    df['Title']=df['Title'].fillna(df['Title'].mode()[0])\n\n    df['Title']=process_texts(df['Title'])\n    df['Review']=process_texts(df['Review'])\n\n    title=get_sequences(df['Title'])\n    reviews=get_sequences(df['Review'])\n\n    df=df.drop(['Title','Review'],axis=1)\n    \n    df=onehot_encode(df,['Company','Model'])\n\n    df=encode_date(df,'Date')\n    \n    \n    #Filling missing value with mean of that column\n\n\n    for column in ['ReviewYear','ReviewMonth','ReviewDay']:\n        df[column]=df[column].fillna(df[column].mean())\n    \n    y=df['Rating']\n    x=df.drop('Rating',axis=1)\n    \n    title_train,title_test,\\\n    reviews_train,reviews_test,\\\n    x_train,x_test,\\\n    y_train,y_test=train_test_split(title,reviews,x,y,train_size=0.7,random_state=123,shuffle=True)\n\n\n    scaler=StandardScaler()\n    scaler.fit(x_train)\n    x_train=pd.DataFrame(scaler.transform(x_train),columns=x_train.columns,index=x_train.index)\n    x_test=pd.DataFrame(scaler.transform(x_test),columns=x_test.columns,index=x_test.index)\n\n\n    \n    return title_train,title_test,reviews_train,reviews_test,x_train,x_test,y_train,y_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.loc[df['Review'].isna(),:].index","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#checking for missing value in the dataset\nx.isna().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"{column:len(df[column].unique()) for column in df.columns}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"title_train,title_test,reviews_train,reviews_test,x_train,x_test,y_train,y_test=preprocess_inputs(df)\nx_train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"title_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reviews_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Constructing the Model\n\n\nx_inputs=tf.keras.Input(shape=(x_train.shape[1],),name='x_inputs')\ndense_1=tf.keras.layers.Dense(64,activation='relu',name='dense_1')(x_inputs)\ndense_2=tf.keras.layers.Dense(64,activation='relu',name='dense_2')(dense_1)\n\n\ntitle_inputs=tf.keras.Input(shape=(title.shape[1],),name='title_inputs')\ntitle_embedding=tf.keras.layers.Embedding(input_dim=5000,output_dim=64,input_length=title.shape[1],name='title_embedding')(title_inputs)\ntitle_flatten=tf.keras.layers.Flatten(name='title_flatten')(title_embedding)\nreviews_inputs=tf.keras.Input(shape=(reviews.shape[1],),name='reviews_inputs')\nreviews_embedding=tf.keras.layers.Embedding(input_dim=5000,output_dim=64,input_length=reviews.shape[1],name='reviews_embedding')(reviews_inputs)\nreviews_flatten=tf.keras.layers.Flatten(name='reviews_flatten')(reviews_embedding)\n\nconcat=tf.keras.layers.concatenate([dense_2,title_flatten,reviews_flatten],name='concatenation')\noutputs=tf.keras.layers.Dense(1,activation='linear')(concat)\n\nmodel=tf.keras.Model(inputs=[x_inputs,title_inputs,reviews_inputs],outputs=outputs)\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tf.keras.utils.plot_model(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='mse')\nhistory=model.fit([x_train,title_train,reviews_train],y_train,validation_split=0.2,batch_size=32,epochs=10,\n                 callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Constructing the Model\nmodel.evaluate([x_test,title_test,reviews_test].y_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x.isna().sum().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"title","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"review","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}